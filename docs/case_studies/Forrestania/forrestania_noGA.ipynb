{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c04eea-4ec5-468f-90aa-0f4bea2b44f3",
   "metadata": {},
   "source": [
    "# Forrestania: Gravity & Magnetics (Pure Python)\n",
    "\n",
    "```{figure} ./images/landing.png\n",
    "---\n",
    "scale: 30%\n",
    "align: right\n",
    "---\n",
    "```\n",
    "\n",
    "This case study focuses on the standalone and joint inversion of airborne magnetic data and synthetic gravity data. The magnetic data were downloaded from the [Geoscience Australia GADDS Portal](https://portal.ga.gov.au/persona/gadds), while the gravity data were generated via forward modelling specifically for this exercise based on a derived iso-shell from magnetic inversion results. We cover the following steps:\n",
    "\n",
    "- [Data imports and pre-processing](forrestania-data)\n",
    "- [Standalone inversion of gravity data](forrestania-gravity)\n",
    "- [Standalone inversion of magnetic data](forrestania-magnetics)\n",
    "- [Joint cross-gradient inversion](forrestania-joint)\n",
    "- [K-means clustering analysis](forrestania-kmeans)\n",
    "\n",
    "```{note}\n",
    "The steps taken in this tutorial are strongly based on the official [SimPEG Tutorials](https://simpeg.xyz/user-tutorials/).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc3883-3166-46bf-8ac8-40b5766cc030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary Python libraries for data handling and visualization\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "import discretize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas\n",
    "import scipy as sp\n",
    "import simpeg\n",
    "from geoh5py import Workspace, objects\n",
    "from PIL import Image\n",
    "\n",
    "# Import SimPEG library\n",
    "from simpeg import (\n",
    "    dask,  # Parallel version of the code\n",
    "    potential_fields,\n",
    ")\n",
    "\n",
    "# Mira Geoscience specific libraries\n",
    "from simpeg_drivers import assets_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4638415a-bea8-4c31-b467-79cb864aeba9",
   "metadata": {},
   "source": [
    "## Geological setting\n",
    "\n",
    "The Forrestania Greenstone Belt, located in the Youanmi Terrane of the Eastern Yilgarn Craton, hosts significant Ni-Cu-PGE mineralisation, primarily within komatiitic units (Frost, 2003; Collins et al., 2012). The belt is structurally complex, featuring synclines, faults, and shear zones that play a key role in sulphide localisation. It is bounded by granitic and gneissic basement, intruded by monzogranite and granodiorite, and transected by Proterozoic dolerite dykes (Perring et al., 1995). Multiple deformation events have remobilised nickel sulphides from their original host rocks into footwall sediments and granitic intrusions, resulting in both typical and atypical mineralisation styles, including granite-hosted sulphides (Collins et al., 2012).\n",
    "\n",
    "The study area is underlain mainly by granitic rocks, forming the basement to the Parker-Range–Hatters Hill greenstone belt immediately to the east. This N–S-trending belt is the main regional host of nickel sulphide deposits, which occur within narrow ultramafic units in an Archaean sequence of metabasalts and sulphidic sediments. Notable nearby deposits include Beautiful Sunday, Flying Fox, and New Morning.\n",
    "\n",
    "A prominent high-magnetic anomaly, trending E–W to ENE–WSW, lies immediately west of the greenstone belt. The anomaly’s orientation, strength, and coincident elevated nickel-in-soil geochemistry suggest it may represent a mafic intrusion—making it a key target for the current geophysical inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463eea7-04b6-466a-aa35-58269605c353",
   "metadata": {},
   "source": [
    "(forrestania-data-os)=\n",
    "## Data Preparation\n",
    "\n",
    "This step involves importing and formatting the necessary datasets for inversion using Mira Geoscience's libraries. For your own inversion projects, you may streamline the data preparation process by using standard Python libraries, depending on your specific needs.\n",
    "\n",
    "### Download and unzip the dataset\n",
    "\n",
    "We first need to unzip the package and import the data into a usable format.\n",
    "\n",
    "The zipped package contains the following three files:\n",
    " - Airborne magnetic survey: `60472_AOI4.csv`\n",
    " - Ground gravity survey: `Forrestania_Gravity_Station_trim_.csv`\n",
    " - Digital Elevation Model (DEM): `Forrestania_SRTM1 Australia_MGA50.tiff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e41088-e8ae-4507-a4be-b449b9abbdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for extracting the zip contents\n",
    "temp_dir = Path(mkdtemp())\n",
    "\n",
    "# Use the `assets_path()` from Mira Geoscience's simpeg_drivers to download and locate the Forrestania dataset\n",
    "# This gives us the full path to the zip file we want to extract\n",
    "file = assets_path() / r\"Case studies/Forrestania_SRTM1 Australia_MGA50_CSV.zip\"\n",
    "\n",
    "# Print the resolved path to confirm where the file is located on disk\n",
    "print(f\"Dataset path: {file}\")\n",
    "\n",
    "# Extract all contents of the zip file into the temporary directory\n",
    "with zipfile.ZipFile(file, \"r\") as zf:\n",
    "    zf.extractall(temp_dir)\n",
    "\n",
    "# List all the files that were extracted\n",
    "files = list(temp_dir.iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc25724",
   "metadata": {},
   "source": [
    "### Load the CSV and geotiff files\n",
    "We will use the `pandas` library to read the CSV files and Mira Geoscience's `geoh5py` library to read the geotiff file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa120922-5c49-4836-99a0-dce07c1bc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_survey = pandas.read_csv(next(file for file in files if \"Gravity\" in file.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b0497-6e67-43ac-b0c5-ce82d1651b2e",
   "metadata": {},
   "source": [
    "### Processing Elevation Data\n",
    "\n",
    "#### Step 1: Convert the geoImage to a 2D Grid with values\n",
    "\n",
    "We will utilize the functionality made available in the `geoh5py` library to read and convert the geotiff to a gridded DEM with geographic coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f32387-ee65-4e39-940c-e0577155ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the elevation GeoTIFF using geoh5py\n",
    "ws = Workspace()\n",
    "geotiff = objects.GeoImage.create(\n",
    "    ws, image=str(next(file for file in files if \"SRTM1\" in file.name))\n",
    ")\n",
    "\n",
    "# Register the geospatial reference system from the TIFF metadata using geoh5py\n",
    "geotiff.georeferencing_from_tiff()\n",
    "\n",
    "# Convert the image into a grid object (2D array of elevations) in geoh5py\n",
    "grid = geotiff.to_grid2d()\n",
    "elevations = grid.children[0].values  # Extract elevation values\n",
    "\n",
    "# Visualise the raw elevation data (some values may be small placeholders, zeros or NaNs)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "elev_image = elevations.reshape(grid.shape, order=\"F\").T\n",
    "im = ax.imshow(elev_image, cmap=\"terrain\", origin=\"lower\")\n",
    "\n",
    "cbar = plt.colorbar(im, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Raw Elevation (m)\")\n",
    "\n",
    "ax.set_title(\"Raw Elevation Grid (including placeholders or NaNs)\")\n",
    "ax.set_xlabel(\"Grid X\")\n",
    "ax.set_ylabel(\"Grid Y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259fa2da-421a-456c-ae25-6f54f8154a26",
   "metadata": {},
   "source": [
    "#### Clean Up Invalid Elevation Values\n",
    "We also need to remove the zeros from the rotated DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd89f2-4130-4c90-a175-7f2c64b2b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check minimum elevation value\n",
    "print(f\"Minimum elevation value: {np.nanmin(elevations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c073a4-d83a-4aa2-8356-20e0d74f9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some elevation values are tiny placeholders for \"no data\", replace with NaN\n",
    "logic = np.abs(elevations) < 2e-38\n",
    "elevations = np.where(logic, np.nan, elevations)\n",
    "\n",
    "# Plot cleaned-up elevation map\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cleaned_elev_image = elevations.reshape(grid.shape, order=\"F\").T\n",
    "im = ax.imshow(cleaned_elev_image, cmap=\"terrain\", origin=\"lower\")\n",
    "\n",
    "cbar = plt.colorbar(im, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Cleaned Elevation (m)\")\n",
    "\n",
    "ax.set_title(\"Cleaned Elevation Grid (NaNs filtered)\")\n",
    "ax.set_xlabel(\"Grid X\")\n",
    "ax.set_ylabel(\"Grid Y\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e59616c-9998-44d7-9fff-618cf9e92d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our final DEM DEM array: [X, Y, Elevation]\n",
    "dem = np.c_[grid.centroids[:, :2], elevations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378442be-d578-4384-8e40-9695fb1c2f71",
   "metadata": {},
   "source": [
    "### Magnetic Data Processing\n",
    "\n",
    "#### Step 1: Extract the magnetic data and format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf5e6c-32aa-42fa-983a-863d343a6a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load magnetic and gravity CSVs with pandas\n",
    "mag_dataframe = pandas.read_csv(next(file for file in files if \"AOI4\" in file.name))\n",
    "\n",
    "# Preview the dataset\n",
    "print(\"Magnetic survey data preview:\")\n",
    "mag_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675ab3f-4126-42dd-8860-7acec8dc7a78",
   "metadata": {},
   "source": [
    "#### Step 2: Attach elevation to the airborne magnetic data\n",
    "\n",
    "There are a lot more information that we need from the original CSV, but also some that are missing.\n",
    "Absolute elevations for this survey are currently not available, only the height above the DEM. So we will need to extract it from the grid.\n",
    "The fastest interpolation is a nearest neighbour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f048cf-2f8e-48b0-b45a-83910a06cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns: projected easting (X), northing (Y), and radar altimeter (height above terrain)\n",
    "mag_locs = mag_dataframe[[\"X_MGA50\", \"Y_MGA50\", \"RADALT\"]].to_numpy()\n",
    "\n",
    "# Build a KDTree for fast spatial search on the DEM 2D coordinates\n",
    "tree = sp.spatial.cKDTree(dem[:, :2])  # Only XY from DEM\n",
    "_, ind = tree.query(mag_locs[:, :2])  # Nearest neighbour indices from DEM\n",
    "\n",
    "# Add DEM ground elevation to RADALT to get true elevation\n",
    "mag_locs[:, 2] += dem[ind, 2]\n",
    "\n",
    "# Check elevation range\n",
    "print(f\"Maximum interpolated elevation: {np.nanmax(mag_locs[:, 2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd25184-6781-4baa-ae2b-e08126359f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the survey points coloured by interpolated elevation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sc = ax.scatter(\n",
    "    mag_locs[:, 0],\n",
    "    mag_locs[:, 1],  # X and Y coordinates\n",
    "    c=mag_locs[:, 2],  # Color is based on elevation\n",
    "    marker=\"o\",  # Circle markers\n",
    "    cmap=\"terrain\",\n",
    "    s=4,  # Size of points slightly larger for visibility\n",
    "    edgecolors=\"none\",\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Interpolated Elevation (m)\")\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Magnetic Flight Path with Interpolated Elevation\")\n",
    "ax.set_xlabel(\"Easting (MGA50)\")\n",
    "ax.set_ylabel(\"Northing (MGA50)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6178d2e-2b61-4bf7-8673-dc92738b5674",
   "metadata": {},
   "source": [
    "#### Step 3: Compute residual data\n",
    "\n",
    "The source of the magnetic signal can generally be attributed to the presence or destruction of magnetic minerals in rocks (mainly magnetite). Magnetometers measure the Total Magnetic Intensity (TMI), which includes both the primary (source) field and secondary fields (signal) from the local geology. \n",
    "\n",
    "The inversion routine requires Residual Magnetic Intensity (RMI). The first step is to compute and remove the primary field (IGRF) at the time and location of acquisition.  The survey was conducted between February and March 1988.\n",
    "\n",
    "##### Lookup/remove IGRF \n",
    "\n",
    "Information about the inducing field strength at the time and location of the survey can be accessed from the [NOAA site](https://www.ngdc.noaa.gov/geomag/calculators/magcalc.shtml?useFullSite=true#igrfwmm).\n",
    "\n",
    "The **inducing field parameters** calculated at the time and location of the survey are\n",
    "\n",
    "```{figure} ./images/NOAA_IGRF.png\n",
    "---\n",
    "scale: 20%\n",
    "---\n",
    "[Click to enlarge]\n",
    "```\n",
    "\n",
    "- Magnitude: 59294 nT\n",
    "- Inclination: -67.1$\\degree$\n",
    "- Declination: -0.89$\\degree$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026be717-7bf5-40b0-8f76-7c07cce49b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the data by the inducing field strength\n",
    "mag_data = mag_dataframe[\"MAGCOMP\"] - 59294\n",
    "fig, ax = plt.subplots()\n",
    "im = plt.hist(mag_data, bins=100)\n",
    "ax.set_aspect(1)\n",
    "print(f\"Median: {mag_data.median()} nT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb824dd-4cc1-468d-9e57-0cfdcdddb712",
   "metadata": {},
   "source": [
    "#### Step 4: Detrend\n",
    "The local background field appears to be slightly lower (~283 nT) than the computed IGRF model, as most of the data away from the main anomaly are below 0. To avoid modelling this background trend, we can remove the median value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6db14f8-b29f-4d11-953a-430b80cfc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_data -= mag_data.median()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = plt.hist(mag_data, bins=100)\n",
    "ax.set_aspect(1)\n",
    "print(f\"Median: {mag_data.median()} nT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75825d5a-d08f-469f-b01b-eb851aebfba6",
   "metadata": {},
   "source": [
    "#### Step 5: Downsampling\n",
    "\n",
    "We can downsample the data along lines to reduce the computation cost of the inversion. Since the average flight height of this survey was 60 m, we can confidently downsample the lines by the same amount without affecting the wavelengths contained in the data.\n",
    "\n",
    "We can do this fairly efficiently by sampling the data over a regular grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4996f62-2ee1-4c19-b57d-5b54f1c69d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid, y_grid = np.meshgrid(\n",
    "    np.arange(745500, 748500, 60),\n",
    "    np.arange(6415500, 6418500, 60),\n",
    ")\n",
    "\n",
    "# Generate a KDTree from the survey\n",
    "tree = sp.spatial.cKDTree(mag_locs[:, :2])\n",
    "\n",
    "# Find the nearest indices for each grid points\n",
    "_, ind = tree.query(np.c_[x_grid.flatten(), y_grid.flatten()])\n",
    "\n",
    "mag_survey = np.c_[mag_locs, mag_data][ind, :]\n",
    "print(mag_survey.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2690fe89-6802-4b45-80eb-ab46db97a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the survey points coloured by interpolated elevation\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sc = ax.scatter(\n",
    "    mag_survey[:, 0],\n",
    "    mag_survey[:, 1],  # X and Y coordinates\n",
    "    c=mag_survey[:, -1],  # Color is based on elevation\n",
    "    marker=\"o\",  # Circle markers\n",
    "    cmap=\"rainbow\",\n",
    "    s=10,  # Size of points slightly larger for visibility\n",
    "    edgecolors=\"none\",\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Magnetic data (nT)\")\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Residual (detrended) data downsampled at 60 m\")\n",
    "ax.set_xlabel(\"Easting (MGA50)\")\n",
    "ax.set_ylabel(\"Northing (MGA50)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd15a36f",
   "metadata": {},
   "source": [
    "(forrestania-gravity-os)=\n",
    "## Gravity data processing\n",
    "\n",
    "The last dataset to format is the gravity survey. In this case, the survey is already located at the surface, and the data is already provided as terrain corrected (2.67 g/cc) in mGal. No extra transformation is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e58daf4-952a-4b2e-ab0c-85adaec56f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the two CSVs with pandas\n",
    "grav_dataframe = pandas.read_csv(next(file for file in files if \"Gravity\" in file.name))\n",
    "grav_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ad5c4-433d-4c0e-a61b-098c8e0ace75",
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_survey = grav_dataframe.to_numpy()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sc = ax.scatter(\n",
    "    grav_survey[:, 0],\n",
    "    grav_survey[:, 1],  # X and Y coordinates\n",
    "    c=grav_survey[:, -1],  # Color is based on elevation\n",
    "    marker=\"o\",  # Circle markers\n",
    "    cmap=\"RdBu_r\",\n",
    "    s=10,  # Size of points slightly larger for visibility\n",
    "    edgecolors=\"none\",\n",
    ")\n",
    "\n",
    "cbar = plt.colorbar(sc, orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Gravity data (mGal)\")\n",
    "\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Terrain corrected (2.67 g/cc) gravity data\")\n",
    "ax.set_xlabel(\"Easting (MGA50)\")\n",
    "ax.set_ylabel(\"Northing (MGA50)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522c0bb5-ecbc-4585-b830-c9cf57724582",
   "metadata": {},
   "source": [
    "## Inversion\n",
    "\n",
    "### Magnetic\n",
    "\n",
    "We begin our analysis with the airborne magnetic survey. Our goal is to model the shape and position of magnetized geological units in 3D.\n",
    "\n",
    "#### Create a mesh \n",
    "\n",
    "We need to break down the subsurface into a grid of cells under the following considerations: use the least number of cells to remain computationally efficient while having enough resolution to model small features accurately. We can achieve both goals with an octree mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d027f-3f22-423b-97a9-ae350818406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the smallest cell size, half the flight height and data resolution\n",
    "base_cells = [30, 30, 30]\n",
    "\n",
    "# Create the base TreeMesh grid (without refinement)\n",
    "mag_octree = discretize.utils.mesh_builder_xyz(\n",
    "    mag_survey[:, :3],\n",
    "    base_cells,\n",
    "    mesh_type=\"tree\",\n",
    "    depth_core=2000,  # At least as deep as 2000 m\n",
    ")\n",
    "\n",
    "\n",
    "# Refine around each receiver location\n",
    "mag_octree.refine_points(\n",
    "    mag_survey[:, :3],\n",
    "    level=-1,  # Use the (last) highest level\n",
    "    padding_cells_by_level=[6, 6, 6],  # Number of cells at 30 m, 60 m and 120 m\n",
    "    finalize=False,\n",
    ")\n",
    "\n",
    "# Refine along topography\n",
    "mag_octree.refine_surface(\n",
    "    dem,\n",
    "    level=-3,  # Only refine at 120 m on dem\n",
    "    padding_cells_by_level=[1],\n",
    "    finalize=True,  # Complete the mesh on our last call\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c53ef-47c8-4658-a8c9-7afc32df7e40",
   "metadata": {},
   "source": [
    "#### Defining the air-ground domains\n",
    "\n",
    "We need to tell the inversion what part of the octree grid lies below the surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740adf64-a3fc-45ba-9236-1701808e15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = discretize.utils.active_from_xyz(mag_octree, dem)\n",
    "n_actives = int(active.sum())\n",
    "print(f\"Number of active cells: {n_actives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa89d83-09c2-4df2-ad37-5531f93f6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "mag_octree.plot_slice(active, normal=\"Y\", grid=True, ax=ax)\n",
    "ax.set_xlim([744500, 749500])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df872cd7-6c91-410d-9295-3dd382398641",
   "metadata": {},
   "source": [
    "#### Defining a survey and simulation\n",
    "\n",
    "We now define the \"geophysical\" experiment in terms of survey configurations, and tell SimPEG how to simulate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80feb0f6-6ade-429b-90e0-e9b93c2f4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a survey with receivers\n",
    "receiver_list = potential_fields.magnetics.receivers.Point(\n",
    "    mag_survey[:, :3], components=[\"tmi\"]\n",
    ")\n",
    "\n",
    "# Define the inducing field parameter (\"the source\")\n",
    "source_field = potential_fields.magnetics.sources.UniformBackgroundField(\n",
    "    receiver_list=receiver_list,\n",
    "    amplitude=59294,\n",
    "    inclination=-67.1,\n",
    "    declination=-0.89,\n",
    ")\n",
    "\n",
    "# Define the survey\n",
    "survey = potential_fields.magnetics.survey.Survey(source_field)\n",
    "\n",
    "# Put it all together\n",
    "simulation = potential_fields.magnetics.simulation.Simulation3DIntegral(\n",
    "    survey=survey,\n",
    "    mesh=mag_octree,\n",
    "    active_cells=active,\n",
    "    chiMap=simpeg.maps.IdentityMap(nP=n_actives),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459dc5a-2a64-4071-b079-0853bf7ae6e1",
   "metadata": {},
   "source": [
    "#### Convert to a Simpeg Data\n",
    "\n",
    "We can create a SimPEG survey that defines the position, data type and specs about the inducing field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5aad9-130e-4064-867a-806e8802cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data class that contains everything\n",
    "data = simpeg.Data(\n",
    "    survey,\n",
    "    dobs=mag_survey[:, -1],\n",
    "    standard_deviation=50,  # Assign the data uncertainty to a quarter of the standard deviation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e6aae9-3dce-4453-9d00-aad2d9d86217",
   "metadata": {},
   "source": [
    "#### Define the data misfit function\n",
    "\n",
    "One of main requirement for the inversion is to fine a model that can replicate the observed data. We enforce that constraint with a least-square measure of data fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83480d40-0310-4b8d-9fa7-fafbfc3a458d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_misfit = simpeg.data_misfit.L2DataMisfit(data=data, simulation=simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d8eb37-acf0-4ed6-9eab-83011e6dfd2f",
   "metadata": {},
   "source": [
    "#### Create the regularization function\n",
    "\n",
    "In order to constrain the model, we need to add a `regularization` function. We will use a function that can promote sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5c04c-869d-41e6-aec1-a22d0d897bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = simpeg.regularization.Sparse(\n",
    "    mag_octree,\n",
    "    active_cells=active,\n",
    "    reference_model=np.zeros(n_actives),\n",
    "    norms=[0, 2, 2, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42527ec-b8f5-45d5-b0ee-75cd6f4c60ef",
   "metadata": {},
   "source": [
    "#### Define inversion directives\n",
    "\n",
    "We want to control the different steps of the inversions, such as:\n",
    " - Initial trade-off parameter\n",
    " - Cooling schedule for data fit\n",
    " - Sparsity promoting iterations and target\n",
    "\n",
    "This is done through `Directives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd068a75-cb5b-4ac1-b2e6-6706bdc295d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_weights = simpeg.directives.UpdateSensitivityWeights(every_iteration=False)\n",
    "starting_beta = simpeg.directives.BetaEstimate_ByEig(beta0_ratio=10)\n",
    "update_jacobi = simpeg.directives.UpdatePreconditioner(update_every_iteration=True)\n",
    "update_irls = simpeg.directives.UpdateIRLS(max_irls_iterations=25)\n",
    "\n",
    "directives_list = [\n",
    "    update_irls,\n",
    "    sensitivity_weights,\n",
    "    starting_beta,\n",
    "    update_jacobi,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e231f80-1283-4b66-aef1-4f2529a9c527",
   "metadata": {},
   "source": [
    "#### Define the inverse problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff21a45-56e4-4e9e-934c-78776d689f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization strategy\n",
    "optimizer = simpeg.optimization.ProjectedGNCG(\n",
    "    lower=0.0,  # Apply a lower bound to the model\n",
    "    maxIter=25,\n",
    ")\n",
    "\n",
    "# Define an inverse problem, the inversion and run\n",
    "inv_problem = simpeg.inverse_problem.BaseInvProblem(\n",
    "    data_misfit, regularization, optimizer\n",
    ")\n",
    "inversion = simpeg.inversion.BaseInversion(inv_problem, directives_list)\n",
    "\n",
    "# Create a simple starting model\n",
    "m_start = np.ones(active.sum()) * 1e-4\n",
    "rec_model = inversion.run(m_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acedad43-ba34-4a50-a247-7a986373518f",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d65db-46e2-4540-9263-d0983849566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate observed versus predicted\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "simpeg.utils.plot_utils.plot2Ddata(mag_survey[:, :2], mag_survey[:, -1], ax=ax)\n",
    "ax.set_title(\"Observed\")\n",
    "\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "simpeg.utils.plot_utils.plot2Ddata(mag_survey[:, :2], inv_problem.dpred[0], ax=ax)\n",
    "ax.set_title(\"Predicted\")\n",
    "\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "simpeg.utils.plot_utils.plot2Ddata(\n",
    "    mag_survey[:, :2], mag_survey[:, -1] - inv_problem.dpred[0], ax=ax\n",
    ")\n",
    "ax.set_title(\"Residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fe34a-71d6-4827-a3cf-dbc00cb223ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to ignore inactive cells when plotting\n",
    "plotting_map = simpeg.maps.InjectActiveCells(mag_octree, active, np.nan)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "im = mag_octree.plot_slice(\n",
    "    plotting_map * inv_problem.l2model, normal=\"Z\", ind=85, ax=ax, clim=[0, 0.25]\n",
    ")\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([6415500, 6418500])\n",
    "ax.set_aspect(1)\n",
    "cbar = plt.colorbar(im[0], orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Susceptibility (SI)\")\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "im = mag_octree.plot_slice(\n",
    "    plotting_map * inv_problem.l2model, normal=\"Y\", ind=70, ax=ax, clim=[0, 0.25]\n",
    ")\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([-1000, 500])\n",
    "ax.set_aspect(1)\n",
    "\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "im = mag_octree.plot_slice(\n",
    "    plotting_map * rec_model, normal=\"Z\", ind=85, ax=ax, clim=[0, 2.0]\n",
    ")\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([6415500, 6418500])\n",
    "ax.set_aspect(1)\n",
    "cbar = plt.colorbar(im[0], orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Susceptibility (SI)\")\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "im = mag_octree.plot_slice(\n",
    "    plotting_map * rec_model, normal=\"Y\", ind=70, ax=ax, clim=[0, 2.0]\n",
    ")\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([-1000, 500])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3649fe4-2118-46ad-8c22-1e2b1cb32a4e",
   "metadata": {},
   "source": [
    "We note the following:\n",
    "\n",
    " - It took 9 iterations to converge to the target misfit.\n",
    " - The following 21 iterations have increased the model complexity ($phi_m$) while preserving the data fit ($phi_d$).\n",
    " - Small anomalies are under-fitted, which could warrant a second inversion with lower uncertainties.\n",
    "\n",
    "The smooth solution (iteration 9) indicates the presence of a susceptible body at depth. The shape and location of the anomaly resemble the solution obtained with the gravity modelling, including the presence of smaller \"fuzzy\" anomalies at the margins.  \n",
    "\n",
    "As an alternative solution, the compact model (iteration 23) recovers a well-defined dense body within a mostly uniform background. Susceptibility contrasts have substantially increased in the range of [0.0, 2.0] SI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c39e9c-c7a5-4610-9c60-cac1e955fb19",
   "metadata": {},
   "source": [
    "(forrestania-magnetics-os)=\n",
    "### Gravity\n",
    "\n",
    "We follow up with the processing of the ground gravity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42554318-435d-498d-950a-0a051c1c2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the smallest cell size, half the flight height and data resolution\n",
    "base_cells = [30, 30, 30]\n",
    "\n",
    "# Create the base TreeMesh grid (without refinement)\n",
    "grav_octree = discretize.utils.mesh_builder_xyz(\n",
    "    mag_survey[:, :3],  # Keep the same extent towards the joint\n",
    "    base_cells,\n",
    "    mesh_type=\"tree\",\n",
    "    depth_core=2000,  # At least as deep as 2000 m\n",
    ")\n",
    "\n",
    "\n",
    "# Refine around each receiver location\n",
    "grav_octree.refine_points(\n",
    "    grav_survey[:, :3],\n",
    "    level=-1,  # Use the (last) highest level\n",
    "    padding_cells_by_level=[6, 6, 6],  # Number of cells at 30 m, 60 m and 120 m\n",
    "    finalize=False,\n",
    ")\n",
    "\n",
    "# Refine along topography\n",
    "grav_octree.refine_surface(\n",
    "    dem,\n",
    "    level=-3,  # Only refine at 120 m on dem\n",
    "    padding_cells_by_level=[1],\n",
    "    finalize=True,  # Complete the mesh on our last call\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4d5ff-ed79-474a-8ce3-06fb743cd523",
   "metadata": {},
   "source": [
    "#### Defining the air-ground domains\n",
    "\n",
    "We need to tell the inversion what part of the octree grid lies below the surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8709eb9b-55c9-4583-91b0-19bd637b64c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active = discretize.utils.active_from_xyz(grav_octree, dem)\n",
    "n_actives = int(active.sum())\n",
    "print(f\"Number of active cells: {n_actives}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c00ec-eae0-4239-9272-9500df458634",
   "metadata": {},
   "source": [
    "#### Defining a survey and simulation\n",
    "\n",
    "We now define the \"geophysical\" experiment in terms of survey configurations, and tell SimPEG how to simulate data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2093b8c-cdb1-40d8-9a9f-7a5f650858c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a survey with receivers\n",
    "receiver_list = potential_fields.gravity.receivers.Point(\n",
    "    grav_survey[:, :3], components=[\"gz\"]\n",
    ")\n",
    "\n",
    "# Define the inducing field parameter (\"the source\")\n",
    "source_field = potential_fields.gravity.sources.SourceField(receiver_list=receiver_list)\n",
    "\n",
    "# Define the survey\n",
    "survey = potential_fields.gravity.survey.Survey(source_field)\n",
    "\n",
    "# Put it all together\n",
    "simulation = potential_fields.gravity.simulation.Simulation3DIntegral(\n",
    "    survey=survey,\n",
    "    mesh=grav_octree,\n",
    "    active_cells=active,\n",
    "    rhoMap=simpeg.maps.IdentityMap(nP=n_actives),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea9a70-2024-442e-bb4d-868401ef14f7",
   "metadata": {},
   "source": [
    "#### Convert to a Simpeg Data\n",
    "\n",
    "We can create a SimPEG survey that defines the position, data type and specs about the inducing field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c3ce4-fa3d-43a7-9305-8f91aa3a529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data class that contains everything\n",
    "data = simpeg.Data(\n",
    "    survey,\n",
    "    dobs=grav_survey[:, -1],\n",
    "    standard_deviation=0.025,  # Assign the data uncertainty to a quarter of the standard deviation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666f09d7-c17d-4abf-a76c-5b3287b74ae5",
   "metadata": {},
   "source": [
    "#### Define the data misfit function\n",
    "\n",
    "One of main requirement for the inversion is to fine a model that can replicate the observed data. We enforce that constraint with a least-square measure of data fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25897b8c-0890-43e2-8b1c-f3510825f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_misfit = simpeg.data_misfit.L2DataMisfit(data=data, simulation=simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a89b80-5505-4a0e-8f73-673eec715002",
   "metadata": {},
   "source": [
    "#### Create the regularization function\n",
    "\n",
    "In order to constrain the model, we need to add a `regularization` function. We will use a function that can promote sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03eb65f-d8d1-4ef8-ad19-296b97050fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = simpeg.regularization.Sparse(\n",
    "    grav_octree,\n",
    "    active_cells=active,\n",
    "    reference_model=np.zeros(n_actives),\n",
    "    norms=[0, 2, 2, 2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544de5c6-b7b5-4874-8533-951165350403",
   "metadata": {},
   "source": [
    "#### Define inversion directives\n",
    "\n",
    "We want to control the different steps of the inversions, such as:\n",
    " - Initial trade-off parameter\n",
    " - Cooling schedule for data fit\n",
    " - Sparsity promoting iterations and target\n",
    "\n",
    "This is done through `Directives`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3adfe59-0b12-488d-992f-e6069290d50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_weights = simpeg.directives.UpdateSensitivityWeights(every_iteration=False)\n",
    "starting_beta = simpeg.directives.BetaEstimate_ByEig(beta0_ratio=10)\n",
    "update_jacobi = simpeg.directives.UpdatePreconditioner(update_every_iteration=True)\n",
    "update_irls = simpeg.directives.UpdateIRLS(max_irls_iterations=25)\n",
    "\n",
    "directives_list = [\n",
    "    update_irls,\n",
    "    sensitivity_weights,\n",
    "    starting_beta,\n",
    "    update_jacobi,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7106e36-6c53-4cbe-bce8-573f7c40fc44",
   "metadata": {},
   "source": [
    "#### Define the inverse problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201e376-8873-47e2-9a33-8bc462f9701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization strategy\n",
    "optimizer = simpeg.optimization.ProjectedGNCG(maxIter=25)\n",
    "\n",
    "# Define an inverse problem, the inversion and run\n",
    "inv_problem = simpeg.inverse_problem.BaseInvProblem(\n",
    "    data_misfit, regularization, optimizer\n",
    ")\n",
    "inversion = simpeg.inversion.BaseInversion(inv_problem, directives_list)\n",
    "\n",
    "# Create a simple starting model\n",
    "m_start = np.ones(active.sum()) * 1e-4\n",
    "rec_model = inversion.run(m_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d30ce8-689b-4d39-8846-a766dba5b774",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8266cc-0ad2-43d7-9cf1-f88f21b48da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate observed versus predicted\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = plt.subplot(1, 3, 1)\n",
    "simpeg.utils.plot_utils.plot2Ddata(grav_survey[:, :2], grav_survey[:, -1], ax=ax)\n",
    "ax.set_title(\"Observed\")\n",
    "\n",
    "ax = plt.subplot(1, 3, 2)\n",
    "simpeg.utils.plot_utils.plot2Ddata(grav_survey[:, :2], inv_problem.dpred[0], ax=ax)\n",
    "ax.set_title(\"Predicted\")\n",
    "\n",
    "ax = plt.subplot(1, 3, 3)\n",
    "simpeg.utils.plot_utils.plot2Ddata(\n",
    "    grav_survey[:, :2], grav_survey[:, -1] - inv_problem.dpred[0], ax=ax\n",
    ")\n",
    "ax.set_title(\"Residual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6990682-3737-4471-b061-67fbf1c50973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping to ignore inactive cells when plotting\n",
    "plotting_map = simpeg.maps.InjectActiveCells(grav_octree, active, np.nan)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "ax = plt.subplot(2, 2, 1)\n",
    "im = grav_octree.plot_slice(\n",
    "    plotting_map * inv_problem.l2model, normal=\"Z\", ind=85, ax=ax, clim=[-0.1, 0.05]\n",
    ")\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([6415500, 6418500])\n",
    "ax.set_aspect(1)\n",
    "cbar = plt.colorbar(im[0], orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Density constrast (g/cc)\")\n",
    "\n",
    "ax = plt.subplot(2, 2, 3)\n",
    "im = grav_octree.plot_slice(\n",
    "    plotting_map * inv_problem.l2model, normal=\"Y\", ind=70, ax=ax, clim=[-0.1, 0.05]\n",
    ")\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([-1000, 500])\n",
    "ax.set_aspect(1)\n",
    "\n",
    "\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "im = grav_octree.plot_slice(\n",
    "    plotting_map * rec_model, normal=\"Z\", ind=85, ax=ax, clim=[-0.5, 0.05]\n",
    ")\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([6415500, 6418500])\n",
    "ax.set_aspect(1)\n",
    "cbar = plt.colorbar(im[0], orientation=\"horizontal\", pad=0.1)\n",
    "cbar.set_label(\"Density constrast (g/cc)\")\n",
    "\n",
    "ax = plt.subplot(2, 2, 4)\n",
    "im = grav_octree.plot_slice(\n",
    "    plotting_map * rec_model, normal=\"Y\", ind=70, ax=ax, clim=[-0.5, 0.05]\n",
    ")\n",
    "ax.set_aspect(1)\n",
    "ax.set_xlim([745500, 748500])\n",
    "ax.set_ylim([-1000, 500])\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d01dd0-4293-40a2-98cf-b7a966015cb3",
   "metadata": {},
   "source": [
    "We note the following:\n",
    "\n",
    " - It took 13 iterations to converge to the target misfit.\n",
    " - The following 12 iterations have increased the model complexity ($phi_m$) but preserved the data fit ($phi_d$).\n",
    " - Most of the important gravity anomalies appear to be reproduced by the final model.\n",
    "\n",
    "The smooth solution (iteration 10) indicates the presence of a dense anomaly extending at depth with density contrasts ranging from [-0.02, 0.05] g/cc. The negative density contrasts appear to be localized around the main positive anomaly, likely due to the smoothness constraint and the lack of `bound` constraints. Some smaller \"fuzzy\" anomalies are visible at the margins.  \n",
    "\n",
    "As an alternative solution, the compact model (iteration 25) recovers a well-defined dense body within a mostly uniform background. Density contrasts have substantially increased in the range of [0.0, 0.56] g/cc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d7ea6-cfc7-4e4a-9eb5-4125cc972250",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- We have inverted publicly available data over the Forrestania geological province.\n",
    "\n",
    "- Our results suggest the presence of different geological units with distinct density and magnetic susceptibility signatures.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
